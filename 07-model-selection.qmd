# Model Selection
## Formal Justification of Distributional Choice, Model Progression, and Variance Decomposition

---

> **Chapter Context.** This chapter provides the statistical foundation for three claims made implicitly throughout the modelling sequence: that the Zero-Inflated Gamma family is the appropriate distributional choice for this data, that each successive model extension was a genuine improvement rather than an over-fit, and that the final model accounts for a meaningful share of the variance in Australian rainfall. Each claim is addressed through a distinct formal procedure.

---

## Predictive Accuracy and Distributional Calibration

```{r}
#| label: setup-selection
#| include: false

librarian::shelf(
  tidyverse,
  glmmTMB,
  kableExtra,
  lmtest,
  performance,
  here
)

df_final <- read_csv(here::here("data", "df_engineered.csv"))
source(here::here("utils.R"))

if (file.exists(here::here("models/all_models_bundle.RData"))) {
  load(here::here("models/all_models_bundle.RData"))
}

re_data <- select_model_features(df_final, keep_location = TRUE) %>%
  scale_data()
```

```{r}
#| label: ppc-and-metrics
#| echo: true
#| message: false
#| warning: false

df_final$pred_rainfall <- predict(m6_mixed, type = "response")

global_rmse <- sqrt(mean((df_final$rainfall - df_final$pred_rainfall)^2))
global_mae <- mean(abs(df_final$rainfall - df_final$pred_rainfall))

print(paste("Global RMSE:", round(global_rmse, 3), "mm"))
print(paste("Global MAE:", round(global_mae, 3), "mm"))
```

```{r}
#| label: ppc-simulation
#| eval: false

set.seed(123)
sims <- simulate(m6_mixed, nsim = 1000)
subset_sims <- sims[, sample(ncol(sims), 50)]

ppc_data <- bind_cols(
  Observed = re_data$rainfall,
  subset_sims
) %>%
  pivot_longer(
    cols = -Observed,
    names_to = "Simulation",
    values_to = "Simulated_Value"
  )
```

```{r}
#| label: fig-ppc
#| fig-cap: "Posterior Predictive Check. The observed distribution (blue) lies well within the envelope of 50 model-simulated distributions (grey), confirming that the ZIG model replicates the key structural features of the rainfall distribution."
#| fig-width: 10
#| fig-height: 7
#| warning: false
#| message: false

ggplot() +
  geom_density(
    data = ppc_data,
    aes(x = Simulated_Value, group = Simulation),
    color = "gray70",
    size = 0.5,
    alpha = 0.5
  ) +
  geom_density(
    data = re_data,
    aes(x = rainfall),
    color = "#0072B2",
    size = 1.2
  ) +
  coord_cartesian(xlim = c(-1, 20)) +
  labs(
    title = "Posterior Predictive Check",
    subtitle = "Grey lines: 50 datasets simulated from the fitted model. Blue line: observed data.",
    x = "Rainfall (mm)",
    y = "Density"
  ) +
  theme_minimal()
```

The global error metrics provide a compact summary of predictive accuracy across all observations and all locations. The mean absolute error (MAE) of 2.736 mm indicates that the model's point prediction is within 2.7 mm of the actual recorded value on an average day. The root mean squared error (RMSE) of 7.539 mm is substantially larger, reflecting the asymmetric influence of extreme events in this metric: a small number of days on which a major storm was under-predicted by 50 mm or more exerts a disproportionate upward pull on the squared error average. The gap between MAE and RMSE is therefore informative in itself, confirming that prediction errors are not symmetrically distributed but are concentrated in the tail of the distribution.

Point error metrics measure accuracy at the mean but cannot assess whether the model is correctly reproducing the entire shape of the rainfall distribution. A posterior predictive check (PPC) addresses this more demanding criterion. We simulate 50 complete datasets from the fitted model and overlay their empirical densities against the observed distribution. If the model is well-specified, the observed density should be indistinguishable from the simulated envelope.

The result (@fig-ppc) shows close agreement across the full range of the distribution. The peak at 0 mm is reproduced accurately, confirming that the zero-inflation component is generating the correct proportion of dry-day predictions conditional on all covariates. The decay rate of the right tail follows the observed data closely, a property that a Gaussian model structurally cannot achieve given its symmetric support. The model is not merely fitting conditional means: it is correctly representing the probabilistic structure of the underlying climate system.

---

## Justification of the Distributional Family

```{r}
#| label: distribution-comparison-code
#| echo: true
#| eval: false

m_linear <- glmmTMB(
  rainfall ~ humidity3pm +
    dewpoint_9am +
    dewpoint_change +
    pressure_change +
    day_cos +
    day_sin +
    rainfall_ma7 +
    days_since_rain +
    humidity_ma7 +
    rain_yesterday +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development +
    gust_U_EW +
    gust_V_NS +
    wind9am_V_NS +
    wind9am_U_EW +
    (1 | location),
  data = re_data,
  family = gaussian(link = "identity")
)

m_tweedie <- glmmTMB(
  rainfall ~ humidity3pm +
    dewpoint_9am +
    dewpoint_change +
    pressure_change +
    day_cos +
    day_sin +
    rainfall_ma7 +
    days_since_rain +
    humidity_ma7 +
    rain_yesterday +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development +
    gust_U_EW +
    gust_V_NS +
    wind9am_V_NS +
    wind9am_U_EW +
    (1 | location),
  data = re_data,
  family = tweedie(link = "log")
)
```

```{r}
#| label: fig-distribution-comparison
#| fig-cap: "Predictive density comparison across three distributional families. The Gaussian model predicts negative rainfall, a physical impossibility. Both the Tweedie and ZI-Gamma families respect the zero lower bound and approximate the right tail of the observed distribution."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

check_data %>%
  select(rainfall, pred_linear, pred_tweedie, pred_zig) %>%
  pivot_longer(
    cols = -rainfall,
    names_to = "Model",
    values_to = "Prediction"
  ) %>%
  mutate(
    Model = dplyr::recode(
      Model,
      pred_linear = "Linear (Gaussian)",
      pred_tweedie = "Tweedie",
      pred_zig = "ZI-Gamma (Final)"
    )
  ) %>%
  ggplot(aes(x = Prediction, fill = Model)) +
  geom_density(alpha = 0.5) +
  geom_density(
    aes(x = rainfall),
    data = re_data,
    fill = NA,
    color = "black",
    linetype = "dashed",
    size = 1
  ) +
  facet_wrap(~Model, scales = "free") +
  coord_cartesian(xlim = c(-5, 20)) +
  labs(
    title = "Why Distribution Matters",
    subtitle = "Black dashed line: observed data. Coloured fill: predicted density from each model family.",
    x = "Predicted Rainfall (mm)",
    y = "Density"
  ) +
  theme_minimal()
```

Choosing a distributional family is not a cosmetic decision: it determines the support of the predictions, the variance function, and the structure of the likelihood being optimised. Three families were evaluated against the full predictor set to isolate the contribution of the distributional choice from the contribution of the predictors themselves.

**The Gaussian model.** A standard linear mixed model with Gaussian errors generates predictions that extend into negative values. Because the Gaussian distribution has support over the entire real line, the model has no mechanism to prevent this, and negative rainfall is a physical impossibility. Beyond this qualitative failure, the Gaussian assumption also implies a symmetric and constant variance structure, which is incompatible with the heavy right skew and variance-mean dependence that the EDA (@sec-eda) documented extensively. Fitting a Gaussian model to this data is not merely suboptimal; it produces predictions that are fundamentally inconsistent with the properties of the system being modelled.

**The Tweedie model.** The Tweedie distribution with power parameter $p \in (1, 2)$ is a compound Poisson-Gamma distribution that naturally accommodates zero values alongside a continuous positive component. It respects the zero lower bound and can represent right-skewed positive data. However, it models zeros and positive values through a single unified process governed by a single mean parameter and the power index. This is a structural constraint: the probability of a zero and the expected positive value are both driven by the same linear predictor, and they cannot be allowed to respond to different sets of covariates.

**The Zero-Inflated Gamma model.** The ZIG framework relaxes this constraint explicitly. The zero-inflation and conditional intensity components have separate linear predictors, which means predictors of occurrence and predictors of intensity are estimated independently. The EDA provides direct empirical motivation for this separation: the Markov analysis showed that `rain_yesterday` operates primarily through the hurdle, determining whether rain occurs at all, while the pressure change analysis showed that the diurnal pressure signal is more relevant to intensity. These two physical processes do not share the same covariates, and a model that constrains them to do so sacrifices interpretability and predictive accuracy. The ZIG framework gives each process its own parameter vector, making it both more flexible and more physically coherent than the Tweedie alternative.

---

## Progressive Model Selection via Likelihood Ratio Tests

```{r}
#| label: model-progression-lrt
#| echo: true
#| message: false
#| warning: false

lrt_1v0 <- lmtest::lrtest(m0_null, m1_moisture)
lrt_2v1 <- lmtest::lrtest(m1_moisture, m2_temporal)
lrt_3v2 <- lmtest::lrtest(m2_temporal, m3_history)
lrt_4v3 <- lmtest::lrtest(m3_history, m4_energy)
lrt_5v4 <- lmtest::lrtest(m4_energy, m5_wind)
lrt_6v5 <- lmtest::lrtest(m5_wind, m6_mixed)

lrt_results <- tibble(
  Comparison = c(
    "Null vs Moisture",
    "Moisture vs Temporal",
    "Temporal vs History",
    "History vs Energy",
    "Energy vs Wind",
    "Wind vs Mixed Effects"
  ),
  Chi_square = c(
    lrt_1v0$Chisq[2],
    lrt_2v1$Chisq[2],
    lrt_3v2$Chisq[2],
    lrt_4v3$Chisq[2],
    lrt_5v4$Chisq[2],
    lrt_6v5$Chisq[2]
  ),
  df = c(
    lrt_1v0$Df[2],
    lrt_2v1$Df[2],
    lrt_3v2$Df[2],
    lrt_4v3$Df[2],
    lrt_5v4$Df[2],
    lrt_6v5$Df[2]
  ),
  raw_p = c(
    lrt_1v0$`Pr(>Chisq)`[2],
    lrt_2v1$`Pr(>Chisq)`[2],
    lrt_3v2$`Pr(>Chisq)`[2],
    lrt_4v3$`Pr(>Chisq)`[2],
    lrt_5v4$`Pr(>Chisq)`[2],
    lrt_6v5$`Pr(>Chisq)`[2]
  )
) %>%
  mutate(
    adj_p_value = p.adjust(raw_p, method = "holm"),
    Significant = ifelse(
      adj_p_value < 0.001,
      "***",
      ifelse(adj_p_value < 0.01, "**", ifelse(adj_p_value < 0.05, "*", "ns"))
    ),
    AIC_improvement = c(
      AIC(m0_null) - AIC(m1_moisture),
      AIC(m1_moisture) - AIC(m2_temporal),
      AIC(m2_temporal) - AIC(m3_history),
      AIC(m3_history) - AIC(m4_energy),
      AIC(m4_energy) - AIC(m5_wind),
      AIC(m5_wind) - AIC(m6_mixed)
    )
  )

lrt_results %>%
  mutate(
    Chi_square = round(Chi_square, 2),
    AIC_improvement = round(AIC_improvement, 1)
  ) %>%
  kable(
    caption = "Likelihood Ratio Tests: Progressive Model Comparisons (Holm-Corrected)"
  ) %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

```{r}
#| label: tbl-model-selection
#| echo: true

model_selection <- tibble(
  Model = c(
    "M0: Null",
    "M1: Moisture",
    "M2: Temporal",
    "M3: History",
    "M4: Energy",
    "M5: Wind",
    "M6: Mixed Effects"
  ),
  AIC = c(
    AIC(m0_null),
    AIC(m1_moisture),
    AIC(m2_temporal),
    AIC(m3_history),
    AIC(m4_energy),
    AIC(m5_wind),
    AIC(m6_mixed)
  ),
  BIC = c(
    BIC(m0_null),
    BIC(m1_moisture),
    BIC(m2_temporal),
    BIC(m3_history),
    BIC(m4_energy),
    BIC(m5_wind),
    BIC(m6_mixed)
  )
) %>%
  mutate(
    Delta_AIC = AIC - min(AIC),
    AIC_weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC))
  ) %>%
  arrange(AIC)

model_selection %>%
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  kable(caption = "Model Selection Summary: AIC, BIC, and Akaike Weights") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

```{r}
#| label: fig-model-selection
#| fig-cap: "AIC trajectory across the progressive model sequence. Each extension reduces AIC monotonically, confirming that no step introduced net redundancy. The two largest gains correspond to the initial moisture predictors and the final mixed-effects structure."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| message: false

ggplot(
  model_selection,
  aes(
    x = factor(
      Model,
      levels = c(
        "M6: Mixed Effects",
        "M5: Wind",
        "M4: Energy",
        "M3: History",
        "M2: Temporal",
        "M1: Moisture",
        "M0: Null"
      )
    ),
    y = AIC
  )
) +
  geom_point(size = 4, color = "#0072B2") +
  geom_line(aes(group = 1), size = 1, color = "#0072B2", alpha = 0.5) +
  geom_hline(
    yintercept = min(model_selection$AIC),
    linetype = "dashed",
    color = "red"
  ) +
  geom_text(
    aes(label = sprintf("Delta = %.0f", Delta_AIC)),
    vjust = -1,
    size = 3.5,
    fontface = "bold"
  ) +
  labs(
    title = "Model Selection: Progressive AIC Improvement",
    subtitle = "Every extension is confirmed by LRT p < 0.001. Red dashed line marks the best model (M6).",
    x = "Model (ordered by complexity)",
    y = "AIC (lower is better)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
    plot.title = element_text(face = "bold")
  )
```

AIC quantifies the information lost when a given model is used to approximate the true data-generating process, penalising complexity to discourage over-fitting. A monotonically decreasing AIC sequence across progressively more complex models is not guaranteed: it is possible to add predictors that improve the likelihood by less than the penalty incurred for the additional parameters, which would cause the AIC to rise. That every extension in this sequence produced a net AIC reduction confirms that each added component captures genuine signal rather than noise.

The likelihood ratio test provides the corresponding inferential framework. For two nested models, the test statistic $-2 \ln(\mathcal{L}_\text{reduced} / \mathcal{L}_\text{full})$ follows a chi-squared distribution with degrees of freedom equal to the difference in the number of parameters. The null hypothesis is that the additional parameters are jointly zero, meaning the reduced model is adequate. All six comparisons reject this null at $p < 0.001$ after Holm correction for multiple testing. Even the smallest gain in the sequence (wind vectors, M5, $\chi^2 = 608.53$, $df = 4$) represents an improvement that is overwhelmingly unlikely under the null, and not merely a consequence of the large sample size: the chi-squared statistic scales with the improvement in log-likelihood, not with $N$ directly.

The Akaike weights in the selection table provide a further calibration. With a $\Delta\text{AIC}$ of 65,031.5 separating the best and worst models, the weight on M6 rounds to 1.0 to any reasonable decimal precision. There is no realistic information-theoretic case for preferring any earlier model in the sequence.

---

## Variance Decomposition

```{r}
#| label: model-r2
#| echo: true
#| collapse: true

re_test <- lmtest::lrtest(m5_wind, m6_mixed)
print(re_test)

r2_vals <- performance::r2_nakagawa(m6_mixed)

cat(sprintf(
  "\nMarginal R2  (Fixed Effects only): %.4f\n",
  r2_vals$R2_marginal
))
cat(sprintf(
  "Conditional R2 (Fixed + Random Effects):  %.4f\n",
  r2_vals$R2_conditional
))
```

Standard $R^2$ is not directly defined for generalised linear mixed models because the likelihood-based framework does not produce a natural residual sum of squares. Nakagawa's method provides a principled extension by partitioning the total variance in the model into components attributable to fixed effects, random effects, and residual noise, expressed on the latent (link) scale.

The marginal $R^2$ of 0.3498 quantifies the proportion of variance explained by the fixed effects alone: humidity, pressure, wind vectors, seasonality, persistence, and all derived features. The fixed-effects predictors collectively account for 34.9% of the variance in daily rainfall intensity. This is a realistic figure for a system as inherently stochastic as precipitation: the chaotic dynamics of mesoscale atmospheric processes set a fundamental upper bound on predictability from station-level daily observations, and a third of the total variance is a meaningful share of what is structurally predictable.

The conditional $R^2$ of 0.4464 incorporates the additional variance explained by the location-specific random effects. The difference between the two values, 0.0966, represents the share of variance attributable purely to geography: the persistent differences between locations that remain after all dynamic weather variables have been controlled for. Approximately 10% of the total variance in Australian daily rainfall is explained not by what the atmosphere is doing today but by where the measurement station sits on the continent. This quantifies, in a single number, the geographic heterogeneity that the random effects structure was designed to capture and that a fixed-effects-only model would leave in the residuals.

---

## Conclusion

The evidence assembled across this chapter supports the following conclusions. The ZIG distributional family is the appropriate choice for this data: the Gaussian model produces physically impossible predictions and the Tweedie model, while valid, constrains occurrence and intensity to share the same linear predictor in a way that is empirically unjustified. Every step in the progressive model sequence represents a statistically significant improvement, confirmed by likelihood ratio tests at $p < 0.001$ after multiple comparison correction, and the Akaike weight of the final model is effectively 1. The posterior predictive check confirms that the model replicates the distributional shape of Australian rainfall, not only its conditional mean. And the variance decomposition establishes that the final model explains 44.6% of total variance, of which approximately a tenth is attributable to the geographic heterogeneity captured by the random effects.