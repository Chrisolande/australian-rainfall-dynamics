# Model Selection

In this chapter, we justify every modelling decision through formal statistical tests, compare competing distributional families, and quantify the total variance explained by the final model.

```{r}
#| label: setup-selection
#| include: false

librarian::shelf(
  tidyverse,
  glmmTMB,
  kableExtra,
  lmtest,
  performance,
  here
)

df_final <- read_csv(here::here("data", "df_engineered.csv"))
source(here::here("utils.R"))

if (file.exists(here::here("models/all_models_bundle.RData"))) {
  load(here::here("models/all_models_bundle.RData"))
}

re_data <- select_model_features(df_final, keep_location = TRUE) %>%
  scale_data()
```

## Predictive Accuracy and Generative Validity

```{r}
#| label: ppc-and-metrics
#| echo: true
#| fig-cap: "Posterior Predictive Check. The blue line represents the observed distribution of daily rainfall. The gray lines represent 50 simulated datasets generated by the model. The tight overlap confirms that the model correctly captures the heavy skew and zero-inflation of the real climate system."
#| fig-width: 10
#| fig-height: 7
#| message: false
#| warning: false

df_final$pred_rainfall <- predict(m6_mixed, type = "response")

global_rmse <- sqrt(mean((df_final$rainfall - df_final$pred_rainfall)^2))
global_mae <- mean(abs(df_final$rainfall - df_final$pred_rainfall))

print(paste("Global RMSE:", round(global_rmse, 3), "mm"))
print(paste("Global MAE:", round(global_mae, 3), "mm"))
```

```{r}
#| label: ppc-simulation
#| eval: false

set.seed(123)
sims <- simulate(m6_mixed, nsim = 1000)
subset_sims <- sims[, sample(ncol(sims), 50)]

ppc_data <- bind_cols(
  Observed = re_data$rainfall,
  subset_sims
) %>%
  pivot_longer(
    cols = -Observed,
    names_to = "Simulation",
    values_to = "Simulated_Value"
  )
```

```{r}
#| label: plot-ppc
#| warning: false
#| message: false

ggplot() +
  geom_density(
    data = ppc_data,
    aes(x = Simulated_Value, group = Simulation),
    color = "gray70",
    size = 0.5,
    alpha = 0.5
  ) +
  geom_density(
    data = re_data,
    aes(x = rainfall),
    color = "#0072B2",
    size = 1.2
  ) +
  coord_cartesian(xlim = c(-1, 20)) +
  labs(
    title = "Posterior Predictive Check",
    subtitle = "Does the model's imagination (Gray) match reality (Blue)?",
    x = "Rainfall (mm)",
    y = "Density"
  ) +
  theme_minimal()
```

**1. Error Metrics:**

- **Global MAE: 2.71 mm** , on any given day, the model's prediction is within 2.7mm of actual rainfall on average.
- **Global RMSE: 7.48 mm** , the higher value reflects the inherent unpredictability of extreme storm events (e.g., receiving 150mm when 50mm was predicted).

**2. Posterior Predictive Check:** The blue line (Reality) sits perfectly nested within the bundle of gray lines (Model Simulations):

- The peak at 0mm is captured accurately, confirming the Zero-Inflation component is working.
- The decay rate of the right tail matches perfectly , a Gaussian model would have failed here.
- **Conclusion:** The model is not just fitting means; it is successfully replicating the underlying statistical distribution of the climate system.

## Justification of Distributional Choice

```{r}
#| label: distribution-check-code
#| echo: true
#| eval: false

m_linear <- glmmTMB(
  rainfall ~ humidity3pm +
    dewpoint_9am +
    dewpoint_change +
    pressure_change +
    day_cos +
    day_sin +
    rainfall_ma7 +
    days_since_rain +
    humidity_ma7 +
    rain_yesterday +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development +
    gust_U_EW +
    gust_V_NS +
    wind9am_V_NS +
    wind9am_U_EW +
    (1 | location),
  data = re_data,
  family = gaussian(link = "identity")
)

m_tweedie <- glmmTMB(
  rainfall ~ humidity3pm +
    dewpoint_9am +
    dewpoint_change +
    pressure_change +
    day_cos +
    day_sin +
    rainfall_ma7 +
    days_since_rain +
    humidity_ma7 +
    rain_yesterday +
    sunshine +
    evaporation +
    instability_index +
    sun_humid_interaction +
    cloud_development +
    gust_U_EW +
    gust_V_NS +
    wind9am_V_NS +
    wind9am_U_EW +
    (1 | location),
  data = re_data,
  family = tweedie(link = "log")
)
```

```{r}
#| label: fig-distribution-comparison
#| fig-cap: "Why Distribution Matters: Comparing Predictive Densities. The Gaussian model (Red) fails catastrophically by predicting negative rainfall. The ZI-Gamma (Blue) and Tweedie (Green) correctly capture the zero-bound and long right tail of the actual data (Black Dashed Line)."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| warning: false

check_data %>%
  select(rainfall, pred_linear, pred_tweedie, pred_zig) %>%
  pivot_longer(
    cols = -rainfall,
    names_to = "Model",
    values_to = "Prediction"
  ) %>%
  mutate(
    Model = dplyr::recode(
      Model,
      pred_linear = "Linear (Gaussian)",
      pred_tweedie = "Tweedie",
      pred_zig = "ZI-Gamma (Ours)"
    )
  ) %>%
  ggplot(aes(x = Prediction, fill = Model)) +
  geom_density(alpha = 0.5) +
  geom_density(
    aes(x = rainfall),
    data = re_data,
    fill = NA,
    color = "black",
    linetype = "dashed",
    size = 1
  ) +
  facet_wrap(~Model, scales = "free") +
  coord_cartesian(xlim = c(-5, 20)) +
  labs(
    title = "Why Distribution Matters",
    subtitle = "Black Dashed Line = REAL Data.\nNotice Linear predicts impossible negative rain. Tweedie/ZIG capture the shape.",
    x = "Predicted Rainfall (mm)",
    y = "Density"
  ) +
  theme_minimal()
```

**1. The Failure of Linearity (Gaussian):** The Gaussian model is forced to predict **negative rainfall** to fit the mean correctly , physically impossible. It also completely misses the long right tail of extreme storm events.

**2. Tweedie vs. Zero-Inflated Gamma:** Both models respect the physical boundary of zero rainfall and align closely with the real data. However, Tweedie uses a *single process* to model both rain occurrence and intensity. Our EDA (Markov Chain analysis) proved these processes have *different drivers* , `pressure_change` drives occurrence while `wind_vectors` drive intensity. The **Zero-Inflated Gamma** separates these into a Logit model (zero state) and a Gamma model (wet state), resulting in more accurate, physically interpretable predictions.

## Progressive Model Selection

```{r}
#| label: model-progression-lrt
#| echo: true
#| message: false
#| warning: false

lrt_1v0 <- lmtest::lrtest(m0_null, m1_moisture)
lrt_2v1 <- lmtest::lrtest(m1_moisture, m2_temporal)
lrt_3v2 <- lmtest::lrtest(m2_temporal, m3_history)
lrt_4v3 <- lmtest::lrtest(m3_history, m4_energy)
lrt_5v4 <- lmtest::lrtest(m4_energy, m5_wind)
lrt_6v5 <- lmtest::lrtest(m5_wind, m6_mixed)

lrt_results <- tibble(
  Comparison = c(
    "Null vs Moisture",
    "Moisture vs Temporal",
    "Temporal vs History",
    "History vs Energy",
    "Energy vs Wind",
    "Wind vs Mixed Effects"
  ),
  Chi_square = c(
    lrt_1v0$Chisq[2],
    lrt_2v1$Chisq[2],
    lrt_3v2$Chisq[2],
    lrt_4v3$Chisq[2],
    lrt_5v4$Chisq[2],
    lrt_6v5$Chisq[2]
  ),
  df = c(
    lrt_1v0$Df[2],
    lrt_2v1$Df[2],
    lrt_3v2$Df[2],
    lrt_4v3$Df[2],
    lrt_5v4$Df[2],
    lrt_6v5$Df[2]
  ),
  raw_p = c(
    lrt_1v0$`Pr(>Chisq)`[2],
    lrt_2v1$`Pr(>Chisq)`[2],
    lrt_3v2$`Pr(>Chisq)`[2],
    lrt_4v3$`Pr(>Chisq)`[2],
    lrt_5v4$`Pr(>Chisq)`[2],
    lrt_6v5$`Pr(>Chisq)`[2]
  )
) %>%
  mutate(
    adj_p_value = p.adjust(raw_p, method = "holm"),
    Significant = ifelse(
      adj_p_value < 0.001,
      "***",
      ifelse(adj_p_value < 0.01, "**", ifelse(adj_p_value < 0.05, "*", "ns"))
    ),
    AIC_improvement = c(
      AIC(m0_null) - AIC(m1_moisture),
      AIC(m1_moisture) - AIC(m2_temporal),
      AIC(m2_temporal) - AIC(m3_history),
      AIC(m3_history) - AIC(m4_energy),
      AIC(m4_energy) - AIC(m5_wind),
      AIC(m5_wind) - AIC(m6_mixed)
    )
  )

lrt_results %>%
  mutate(
    Chi_square = round(Chi_square, 2),
    AIC_improvement = round(AIC_improvement, 1)
  ) %>%
  kable(caption = "Likelihood Ratio Tests: Progressive Model Building") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

```{r}
#| label: tbl-model-selection
#| tbl-cap: "Model Selection Summary Table"
#| echo: true

model_selection <- tibble(
  Model = c(
    "m0_null",
    "m1_moisture",
    "m2_temporal",
    "m3_history",
    "m4_energy",
    "m5_wind",
    "m6_mixed"
  ),
  AIC = c(
    AIC(m0_null),
    AIC(m1_moisture),
    AIC(m2_temporal),
    AIC(m3_history),
    AIC(m4_energy),
    AIC(m5_wind),
    AIC(m6_mixed)
  ),
  BIC = c(
    BIC(m0_null),
    BIC(m1_moisture),
    BIC(m2_temporal),
    BIC(m3_history),
    BIC(m4_energy),
    BIC(m5_wind),
    BIC(m6_mixed)
  )
) %>%
  mutate(
    Delta_AIC = AIC - min(AIC),
    AIC_weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC))
  ) %>%
  arrange(AIC)

model_selection %>%
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  kable(caption = "Model Selection Table") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

```{r}
#| label: fig-model-selection
#| fig-cap: "Model Selection: Progressive Improvement. The AIC drops significantly at every stage, confirming that no step was redundant. The largest jump occurs when adding moisture variables; the addition of Spatial Mixed Effects (M6) also provides a massive late-stage improvement."
#| fig-width: 10
#| fig-height: 8
#| echo: true
#| message: false

ggplot(
  model_selection,
  aes(
    x = factor(
      Model,
      levels = c(
        "m6_mixed",
        "m5_wind",
        "m4_energy",
        "m3_history",
        "m2_temporal",
        "m1_moisture",
        "m0_null"
      )
    ),
    y = AIC
  )
) +
  geom_point(size = 4, color = "#0072B2") +
  geom_line(aes(group = 1), size = 1, color = "#0072B2", alpha = 0.5) +
  geom_hline(
    yintercept = min(model_selection$AIC),
    linetype = "dashed",
    color = "red"
  ) +
  geom_text(
    aes(label = sprintf("Δ=%.0f", Delta_AIC)),
    vjust = -1,
    size = 3.5,
    fontface = "bold"
  ) +
  labs(
    title = "Model Selection: Progressive Improvement",
    subtitle = "Each step significantly improves fit (LRT p < 0.001 for all comparisons)",
    x = "Model (Ordered by Complexity)",
    y = "AIC (Lower is Better)",
    caption = "Red line = Best Model (M6 Mixed)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
    plot.title = element_text(face = "bold")
  )
```

**1. Monotonic AIC Decrease:** Every model addition reduced AIC , no step was redundant.

- **Largest Gain:** Null → M1 (Moisture): $\Delta AIC \approx 38,000$ , humidity is the primary driver.
- **Final Gain:** M5 → M6 (Mixed Effects): $\Delta AIC \approx 7,600$ , spatial heterogeneity is not a minor nuisance but a fundamental component of the Australian climate system.

**2. Likelihood Ratio Tests:** Every comparison yielded $p < 0.001$. Even the smallest step (Wind Vectors, M5) improved the model significantly ($\chi^2 = 607, df = 4$).

## Variance Explained

```{r}
#| label: model-r2
#| echo: true
#| collapse: true

re_test <- lmtest::lrtest(m5_wind, m6_mixed)
print(re_test)

r2_vals <- performance::r2_nakagawa(m6_mixed)

cat(sprintf(
  "\nMarginal R2  (Fixed Effects only): %.4f\n",
  r2_vals$R2_marginal
))
cat(sprintf(
  "Conditional R2 (Fixed + Random Effects): %.4f\n",
  r2_vals$R2_conditional
))
```

Using Nakagawa's method for GLMMs:

- **Marginal $R^2 = 0.345$:** Our fixed meteorological predictors (Humidity, Wind, Pressure, etc.) explain **34.5%** of the variance in rainfall intensity.
- **Conditional $R^2 = 0.441$:** Including location-specific random effects raises explanatory power to **44.1%**.
- **Insight:** Roughly **10% of the explainable variance** in Australian rainfall is purely geographic , attributable to the city's location (coastal vs. inland) rather than dynamic weather variables.

**Conclusion:** Model 6 (Mixed-Effects Zero-Inflated Gamma) is the statistically superior model. It maximizes likelihood, minimizes information loss (AIC/BIC), passes all diagnostic checks, and captures significant spatial variance that fixed-effects models miss.
