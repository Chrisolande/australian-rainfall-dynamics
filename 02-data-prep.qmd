# Data Preparation {#sec-data}

---

> **Chapter Context.** Before any statistical analysis can proceed, the raw dataset must be transformed into a form that is both analytically tractable and physically credible. This chapter documents three decisions that have downstream consequences throughout the report: the syntactic and temporal standardisation of the raw data, a diagnostic investigation of the structure and mechanism of the missingness, and the design of a two-stage imputation pipeline informed by that investigation. Each decision is motivated by the properties of the data-generating process rather than by computational convenience.

---

## Computational Environment

```{r}
#| label: setup-libraries-data
#| echo: true
#| message: false
#| warning: false
#| results: 'hide'

librarian::shelf(
  tidyverse,
  tidymodels,
  kableExtra,
  patchwork,
  skimr,
  gridExtra,
  gtsummary,
  janitor,
  corrplot,
  sjPlot,
  scales,
  GGally,
  car,
  forcats,
  performance,
  glmmTMB,
  splines,
  mgcv,
  DHARMa,
  zoo,
  ggpubr,
  ggridges,
  caret,
  rstatix,
  Metrics,
  mice,
  missRanger,
  ranger,
  cocor,
  multcompView,
  lmtest,
  aod,
  pROC,
  naniar,
  glue,
  viridis,
  parallel
)

df <- read_csv("data/weatherAUS.csv") %>%
  janitor::clean_names()

source(here::here("utils.R"))
```

The package selection reflects the specific demands of meteorological data analysis. The core wrangling and visualisation toolkit (`tidyverse`, `janitor`, `kableExtra`) handles routine data manipulation. The modelling stack (`glmmTMB`, `DHARMa`, `splines`, `mgcv`) is assembled for the zero-inflated mixed-effects framework documented in later chapters. The imputation stack (`missRanger`, `mice`, `ranger`) supports the Random Forest and chained imputation procedures described below. The missingness diagnostic stack (`naniar`, `glue`) supports the structural analysis in Section 2.3 (@sec-missingness-diagnostics). Libraries are loaded via `librarian`, which installs missing packages automatically and ensures reproducibility across environments.

---

## Initial Cleaning and Standardisation

The raw dataset undergoes three transformations before any missingness analysis or imputation.

```{r}
#| label: data-cleaning
#| echo: true
#| message: false
#| warning: false

df_clean <- df %>%
  mutate(
    date = as.Date(date),
    month = as.factor(month(date)),
    day = as.factor(wday(date, label = TRUE))
  ) %>%
  filter(!is.na(rainfall))

df_clean %>%
  head() %>%
  kable(caption = "Head of Cleaned Dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

df_clean %>%
  tail() %>%
  kable(caption = "Tail of Cleaned Dataset") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

**Column standardisation.** All variable names are converted to `snake_case` via `janitor::clean_names()`, called at ingestion. This eliminates downstream ambiguity in variable references and ensures internal consistency across all chapters.

**Temporal feature extraction.** The `date` column is typed as a `Date` object and two derived features are extracted: `month` (as a factor) and `day` (day of week, labelled). Month captures the seasonal structure of Australian precipitation; day of week is retained as a potential control variable for reporting artefacts in the raw data.

**Target filtering.** Observations where `rainfall` is missing are removed. Records without a ground-truth rainfall measurement have no supervised learning value and cannot contribute to either the hurdle or the intensity component of the ZIG model.

---

## Missingness Diagnostics {#sec-missingness-diagnostics}

Before designing an imputation strategy, it is necessary to understand the mechanism and structure of the missing data. The choice between imputation methods depends critically on three questions: whether missingness is random with respect to other variables in the dataset, whether missing values cluster at specific locations or time periods, and whether the four most-affected variables fail independently or as a coordinated group. A strategy designed without answering these questions risks either under-imputing (discarding recoverable signal) or over-imputing (fabricating data in regions where recovery is not possible). The five analyses below provide the empirical basis for each design decision in the pipeline that follows.

### Co-missingness Structure {#sec-co-missingness}

```{r}
#| label: tbl-co-missingness
#| tbl-cap: "Conditional Co-missingness Matrix"
#| echo: true
#| message: false
#| warning: false

high_miss_cols <- c("sunshine", "evaporation", "cloud3pm", "cloud9am")
high_miss <- high_miss_cols[high_miss_cols %in% names(df)]

cat("High missingness variables:", paste(high_miss, collapse = ", "), "\n\n")

miss_mat <- df %>%
  select(all_of(high_miss)) %>%
  mutate(across(everything(), is.na)) %>%
  as.matrix() %>%
  apply(2, as.integer)

intersection_matrix <- crossprod(miss_mat)
total_miss_counts <- diag(intersection_matrix)

pct_matrix <- intersection_matrix / total_miss_counts * 100

co_missing_stats <- as.data.frame(as.table(pct_matrix)) %>%
  rename(var1 = Var1, var2 = Var2, pct_co_miss = Freq) %>%
  filter(var1 != var2) %>%
  arrange(desc(pct_co_miss))

co_missing_stats %>%
  mutate(
    msg = glue(
      "  {var1} -> {var2}: {round(pct_co_miss, 1)}%  (when {var1} is missing, {var2} is missing)"
    )
  ) %>%
  pull(msg) %>%
  walk(cat, "\n")

co_missing_stats %>%
  kable(
    caption = "Conditional Co-missingness: when var1 is missing, what percentage of the time is var2 also missing?",
    digits = 1,
    col.names = c("Variable 1 (Missing)", "Variable 2", "Co-missing (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

The co-missingness matrix (@tbl-co-missingness) confirms that these four variables fail as a systematic cluster rather than independently. The dependencies are strongest between instrumental pairs: if evaporation is missing, there is a 93.2% probability that sunshine is also missing. Even the weakest relationship in the matrix (sunshine to cloud9am) retains a rate of 67.5%, which is nearly double what would be expected under random failure.

Under MCAR, the co-missing rates would be close to the marginal missingness rates of each variable, roughly 40 to 48%. Rates uniformly between 67% and 93% instead indicate a shared upstream cause: the instrumentation profile of each station. Sunshine recorders, evaporation pans, and cloud coverage sensors are deployed as a package, not individually. A station without one is very likely to lack the others. This is MNAR at the station level. The practical consequence for imputation is that treating the four variables as independently missing would be incorrect: their correlations when observed are available precisely because they fail together, and a multivariate imputation method that exploits those cross-variable relationships will outperform four separate univariate models.

### Temporal Structure and Structural Breaks {#sec-temporal-structure}

```{r}
#| label: fig-temporal-missingness
#| fig-cap: "Timeline of systematic missingness across the four high-missingness variables. The stepped increases visible particularly in sunshine and evaporation indicate structural breaks in data collection rather than random sensor failures."
#| fig-width: 10
#| fig-height: 7
#| echo: true
#| warning: false

temporal_trend <- df %>%
  mutate(month_floor = floor_date(date, "month")) %>%
  select(month_floor, any_of(high_miss)) %>%
  pivot_longer(
    cols = -month_floor,
    names_to = "variable",
    values_to = "value"
  ) %>%
  group_by(month_floor, variable) %>%
  summarise(pct_missing = mean(is.na(value)) * 100, .groups = "drop")

ggplot(
  temporal_trend,
  aes(x = month_floor, y = pct_missing, color = variable)
) +
  geom_line(linewidth = 1) +
  facet_wrap(~variable, scales = "free_y", ncol = 1) +
  labs(
    title = "Timeline of Systematic Missingness",
    subtitle = "Structural breaks appear as step changes rather than random fluctuations",
    y = "Missingness (%)",
    x = "Year"
  ) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 100))
```

The temporal analysis (@fig-temporal-missingness) confirms that missingness is not randomly distributed over time. The cloud cover variables maintain a roughly stable and high missingness rate across the observation window, consistent with a fixed set of stations never having recorded these measurements. The `sunshine` and `evaporation` variables show a distinct stepped pattern: missingness rises at specific breakpoints rather than fluctuating randomly, indicating that certain stations were decommissioned or that recording protocols changed at identifiable calendar dates.

This temporal structure has a direct implication for the interpolation stage of the pipeline. Linear interpolation is appropriate when a smooth trajectory can be inferred from values on either side of a gap. Extended contiguous gaps produced by a structural break have no valid upper boundary from which to interpolate, and filling them with temporal interpolation would create long synthetic sequences with no empirical anchor. The five-day interpolation cap set in Stage 1 of the pipeline is a direct response to this finding.

### Geographic Concentration: Ghost Sensor Identification {#sec-ghost-sensor}

```{r}
#| label: ghost-sensors
#| echo: true
#| message: false
#| warning: false

GHOST_THRESHOLD <- 0.90

location_summary <- df %>%
  group_by(location) %>%
  naniar::miss_var_summary()

ghost_sensors <- location_summary %>%
  filter(variable %in% high_miss, pct_miss > GHOST_THRESHOLD * 100) %>%
  arrange(desc(pct_miss))

ghost_sensors %>%
  kable(
    caption = "Ghost Sensor Instances: Location-Variable Pairs with >90% Missingness",
    digits = 1,
    col.names = c("Location", "Variable", "Missing (n)", "Missing (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

cat(sprintf(
  "\nTotal ghost sensor instances identified: %d across %d locations\n",
  nrow(ghost_sensors),
  n_distinct(ghost_sensors$location)
))
```

The location-level analysis identifies the specific station-variable pairs responsible for the bulk of the aggregate missingness. The top ten instances from the script output, all at exactly 100% missing, are as follows: Albury (`evaporation`, 3,040 observations; `sunshine`, 3,040), BadgerysCreek (`evaporation`, 3,009; `sunshine`, 3,009; `cloud9am`, 3,009; `cloud3pm`, 3,009), Newcastle (`evaporation`, 3,039; `sunshine`, 3,039), and NorahHead (`evaporation`, 3,004; `sunshine`, 3,004). At these stations, the instrument in question recorded a value on zero days across the entire observation window. These are not sensors experiencing intermittent failure; they are sensors that were never present or that were removed before the data collection period began.

The distinction between ghost sensors and ordinary missingness is consequential for imputation. For a gap of five to fifteen consecutive missing days, a Random Forest model can generate reasonable predictions by drawing on correlated variables at the same station and the same variable at nearby stations. For a gap spanning 3,000 or more consecutive observations, this extrapolation has no empirical support whatsoever: there is no observed value at that station and variable combination to anchor or validate the prediction. Values produced for these pairs would be statistically plausible by construction but would carry no physical information about what the instrument would have actually recorded. Ghost sensor pairs are identified before Stage 2 runs and flagged so that their imputed values can be treated with appropriate scepticism in downstream analysis.

### Weather-Conditionality of Sunshine Missingness {#sec-weather-conditionality}

```{r}
#| label: tbl-sunshine-mcar-test
#| echo: true
#| message: false
#| warning: false

if (all(c("rainfall", "sunshine") %in% names(df))) {
  weather_missing_stats <- df %>%
    filter(!is.na(rainfall)) %>%
    mutate(is_rainy = if_else(rainfall > 1, "Rainy (>1mm)", "Dry (<=1mm)")) %>%
    group_by(is_rainy) %>%
    summarise(
      n_obs = n(),
      pct_sunshine_missing = mean(is.na(sunshine)) * 100,
      .groups = "drop"
    )

  print(weather_missing_stats)

  weather_missing_stats %>%
    kable(
      caption = "Sunshine Missingness Rate by Daily Rainfall Status",
      digits = 1,
      col.names = c("Day Type", "Observations (n)", "Sunshine Missing (%)")
    ) %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
}
```

```{r}
#| label: fig-sunshine-rainfall-density
#| fig-cap: "Density of rainfall amounts on days where sunshine data is present versus missing. The near-identical distributions confirm that sunshine missingness is not weather-conditional: the same stations are missing sunshine on both dry and rainy days because the instrument was simply not installed, not because it failed during precipitation events."
#| fig-width: 9
#| fig-height: 6
#| echo: true
#| warning: false

df %>%
  naniar::bind_shadow() %>%
  filter(rainfall > 0 & rainfall < 50) %>%
  ggplot(aes(x = rainfall, fill = sunshine_NA)) +
  geom_density(alpha = 0.6) +
  scale_fill_viridis_d(labels = c("!NA" = "Present", "NA" = "Missing")) +
  labs(
    title = "Does Sunshine go Missing on Rainy Days?",
    subtitle = "Density of rainfall amounts for days with Missing vs. Present sunshine data",
    x = "Rainfall (mm)",
    y = "Density",
    fill = "Sunshine Status"
  ) +
  theme_minimal()
```

A specific concern when imputing a predictor variable is outcome-related missingness: if sunshine sensors failed more often on rainy days, then the imputed values would carry a directional signal about the target variable and could introduce bias into the training data.

The empirical test refutes this concern. The table output (@tbl-sunshine-mcar-test) reports a sunshine missing rate of 47.8% on 110,319 dry days (rainfall at most 1 mm) and 47.2% on 31,880 rainy days (rainfall above 1 mm), a difference of 0.6 percentage points. The density plot (@fig-sunshine-rainfall-density) makes the same point visually: the distribution of rainfall amounts on days with missing sunshine and on days with present sunshine are indistinguishable across the full range from 0 to 50 mm. The slight visual offset in the figure reflects not a systematic pattern but the difference in the sizes of the two groups.

Sunshine missingness is station-conditional rather than weather-conditional. The same stations record missing sunshine on both dry and rainy days at nearly identical rates, because the instrument is absent from those stations entirely. This finding clears the imputation path: there is no outcome-related confound to correct for.

### Missing Pattern Structure

```{r}
#| label: miss-pattern-table
#| echo: true
#| message: false
#| warning: false

cat("Missing pattern combinations:\n")

df %>%
  select(all_of(high_miss)) %>%
  naniar::miss_case_table() %>%
  print()

df %>%
  select(all_of(high_miss)) %>%
  naniar::miss_case_table() %>%
  kable(
    caption = "Distribution of Missing Variable Count per Observation",
    col.names = c(
      "Variables Missing (of 4)",
      "Observations (n)",
      "Percentage (%)"
    )
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

The case-level output from the script reveals a strongly bimodal structure across five distinct patterns. Of all observations: 62,566 (43.0%) have none of the four variables missing; 10,525 (7.2%) have exactly one missing; 20,376 (14.0%) have exactly two missing; 11,378 (7.8%) have exactly three missing; and 40,615 (27.9%) have all four missing simultaneously. The two endpoint categories, zero missing and all four missing, together account for 70.9% of all observations.

The 27.9% with complete simultaneous missingness corresponds directly to the ghost sensor stations identified in @sec-ghost-sensor. For these observations, no imputation is supportable and the values remain missing after the pipeline. The 43.0% with no missingness require no intervention. The substantive imputation work is concentrated in the remaining 29.1% across the three intermediate patterns, where partial instrumentation means that correlated predictors are available to inform the Random Forest estimates. The bimodal structure also confirms that the co-missingness finding is not a statistical artifact: observations genuinely tend to be fully instrumented or minimally instrumented, not randomly partially instrumented.

---

## Imputation Pipeline

The diagnostic evidence from @sec-missingness-diagnostics motivates each design decision in the imputation pipeline. Missingness is station-level rather than weather-conditional (@sec-weather-conditionality), temporally structured with extended contiguous gaps rather than random scatter (@sec-temporal-structure), and co-located across variables at the station level (@sec-co-missingness). These properties rule out simple listwise deletion and mean imputation. They call for a pipeline that respects temporal continuity for smoothly-evolving variables, exploits cross-variable correlations for the structured variables, and declines to impute where the data is genuinely unrecoverable.

### Stage 1: Temporal Interpolation

The eight variables with smooth day-to-day trajectories minimum and maximum temperature, morning and afternoon temperature, morning and afternoon pressure, and morning and afternoon humidity are imputed via linear interpolation grouped by location, bounded by a five-day maximum gap. The five-day cap is set directly in response to the temporal structural break finding: gaps of up to five days lie within a regime where the values at both boundaries sufficiently constrain the trajectory, while longer gaps are associated with structural collection failures that interpolation cannot safely bridge.

### Stage 2: Multivariate Random Forest Imputation

Remaining gaps in `sunshine`, `evaporation`, cloud cover, and wind direction are addressed using `mice` with a Random Forest method. Each variable is imputed from a scientifically motivated predictor set:

- **Cloud cover** (`cloud9am`, `cloud3pm`) from humidity and pressure.
- **Sunshine** from cloud cover, temperature, humidity, location, and month.
- **Evaporation** from wind gust speed, temperature, humidity, sunshine, location, and month.
- **Wind direction** (`wind_gust_dir`, `wind_dir9am`, `wind_dir3pm`) from the corresponding wind speed, pressure, location, and month.

Wind direction is treated as a categorical variable imputed with Random Forest, which handles the multi-class, non-ordinal nature of compass-point directions without imposing a false numeric ordering. Each wind direction variable uses its temporally matched pressure and speed readings as predictors gust direction from gust speed and 3pm pressure, 9am direction from 9am speed and pressure, and 3pm direction from 3pm speed and pressure  preserving the physical coupling between concurrent measurements.

The use of targeted predictor sets is directly motivated by the co-missingness finding. Because the four atmosphere variables tend to be absent together at the station level, their cross-variable correlations when observed are strong and reliable signals for imputation. Restricting each variable's predictor set to physically motivated covariates exploits this structure while reducing the risk of imputing on spurious correlations.

### Ghost Sensor Flagging

Before Stage 2 runs, all station-variable pairs identified in @sec-ghost-sensor as ghost sensors (more than 90% missing across the full observation window) are catalogued and binary missingness flags are attached to the data (`sunshine_imp_flagged`, `evap_imp_flagged`, `cloud3pm_imp_flagged`, `cloud9am_imp_flagged`). These flags serve two purposes: they are excluded from the MICE predictor matrix so they cannot contaminate the imputation model, and they remain in the final dataset as explicit markers of which values are extrapolated with no empirical anchor. Flag columns are also excluded from the predictor matrix alongside the raw date column to prevent data leakage. A Random Forest model has no empirical support for predicting values at a station where an instrument was never present; the flags make this provenance transparent for any downstream analysis that needs to account for it.

```{r}
#| label: imputation-strategy
#| echo: true
#| eval: false

clean_and_impute_weather <- function(df) {
  MAXGAP <- 5
  GHOST_THRESHOLD <- 0.90
  M <- 5

  df <- df %>%
    clean_names() %>%
    mutate(
      date = as.Date(date),
      month = as.factor(month(date)),
      day = as.factor(wday(date, label = TRUE)),
      day_of_year = yday(date),
      wind_gust_dir = as.factor(wind_gust_dir),
      wind_dir9am = as.factor(wind_dir9am),
      wind_dir3pm = as.factor(wind_dir3pm),
      rain_today = as.factor(rain_today),
      location = as.factor(location)
    ) %>%
    filter(!is.na(rainfall)) %>%
    select(-rain_tomorrow)

  # Interpolation
  interp_vars <- c(
    "min_temp",
    "max_temp",
    "temp9am",
    "temp3pm",
    "pressure9am",
    "pressure3pm",
    "humidity9am",
    "humidity3pm"
  )

  df_interp <- df %>%
    group_by(location) %>%
    arrange(date, .by_group = TRUE) %>%
    mutate(across(
      all_of(interp_vars),
      ~ na.approx(., maxgap = MAXGAP, na.rm = FALSE, rule = 2)
    )) %>%
    ungroup()

  # Flag ghost vars
  ghost_prone_vars <- c("sunshine", "evaporation", "cloud3pm", "cloud9am")

  ghost_pairs <- df_interp %>%
    select(location, all_of(ghost_prone_vars)) %>%
    pivot_longer(
      cols = all_of(ghost_prone_vars),
      names_to = "variable",
      values_to = "value"
    ) %>%
    group_by(location, variable) %>%
    summarise(miss_rate = mean(is.na(value)) * 100, .groups = "drop") %>%
    filter(miss_rate > (GHOST_THRESHOLD * 100))

  cat(sprintf("  Found %d ghost sensor instances\n", nrow(ghost_pairs)))

  df_flagged <- df_interp %>%
    mutate(
      sunshine_imp_flagged = as.integer(is.na(sunshine)),
      evap_imp_flagged = as.integer(is.na(evaporation)),
      cloud3pm_imp_flagged = as.integer(is.na(cloud3pm)),
      cloud9am_imp_flagged = as.integer(is.na(cloud9am))
    )

  # MICE setup
  wind_vars <- c("wind_gust_dir", "wind_dir9am", "wind_dir3pm")

  init <- mice(df_flagged, maxit = 0)
  pred <- init$predictorMatrix
  meth <- init$method

  pred[,] <- 0

  meth[ghost_prone_vars] <- "rf"
  meth[wind_vars] <- "rf"

  sun_predictors <- intersect(
    colnames(df_flagged),
    c("cloud9am", "cloud3pm", "max_temp", "humidity3pm", "location", "month")
  )
  evap_predictors <- intersect(
    colnames(df_flagged),
    c(
      "wind_gust_speed",
      "max_temp",
      "humidity3pm",
      "sunshine",
      "location",
      "month"
    )
  )
  cloud_predictors <- intersect(
    colnames(df_flagged),
    c("humidity9am", "humidity3pm", "pressure9am", "location", "month")
  )
  wind_gust_predictors <- intersect(
    colnames(df_flagged),
    c("wind_gust_speed", "pressure3pm", "location", "month")
  )
  wind_9am_predictors <- intersect(
    colnames(df_flagged),
    c("wind_speed9am", "pressure9am", "location", "month")
  )
  wind_3pm_predictors <- intersect(
    colnames(df_flagged),
    c("wind_speed3pm", "pressure3pm", "location", "month")
  )

  if ("sunshine" %in% rownames(pred)) {
    pred["sunshine", sun_predictors] <- 1
  }
  if ("evaporation" %in% rownames(pred)) {
    pred["evaporation", evap_predictors] <- 1
  }
  if ("cloud9am" %in% rownames(pred)) {
    pred["cloud9am", cloud_predictors] <- 1
  }
  if ("cloud3pm" %in% rownames(pred)) {
    pred["cloud3pm", cloud_predictors] <- 1
  }
  if ("wind_gust_dir" %in% rownames(pred)) {
    pred["wind_gust_dir", wind_gust_predictors] <- 1
  }
  if ("wind_dir9am" %in% rownames(pred)) {
    pred["wind_dir9am", wind_9am_predictors] <- 1
  }
  if ("wind_dir3pm" %in% rownames(pred)) {
    pred["wind_dir3pm", wind_3pm_predictors] <- 1
  }

  ignore_cols <- grep("_imp_flagged$|^date$", colnames(pred), value = TRUE)
  pred[, ignore_cols] <- 0

  # Parallel imputation with exact m allocation across cores
  n_cores <- max(1L, min(as.integer(parallel::detectCores()), as.integer(M)))
  m_split <- rep(M %/% n_cores, n_cores)
  if ((M %% n_cores) > 0L) {
    m_split[seq_len(M %% n_cores)] <- m_split[seq_len(M %% n_cores)] + 1L
  }

  seeds <- 123 + seq_len(n_cores) - 1L

  imp_list <- parallel::mclapply(
    seq_len(n_cores),
    function(i) {
      mice(
        df_flagged,
        method = meth,
        predictorMatrix = pred,
        m = m_split[i],
        maxit = 5,
        seed = seeds[i],
        printFlag = FALSE
      )
    },
    mc.cores = n_cores
  )

  # Merge all mids objects into one for MI inference
  imp_merged <- Reduce(ibind, imp_list)
  return(imp_merged)
}
```

```{r}
#| label: clean-and-save-imputed
#| message: false
#| warning: false
#| eval: false

imp_mids <- clean_and_impute_weather(df)
df_final <- complete(imp_mids, action = 1)
write_csv(df_final, "data/df_final.csv")

```

```{r}
#| label: load-imputed-data
#| echo: false
#| message: false
#| warning: false

df_final <- read_csv("data/df_final.csv")
```

---

## Post-Imputation Dataset Properties

The two-stage pipeline produces a dataset whose properties are each traceable to a specific finding from the diagnostic analysis.

**Retention without fabrication.** No observations are discarded on the basis of partial missingness. The 27.9% of observations with all four target variables simultaneously absent are retained with those variables still missing, consistent with the ghost sensor finding that no empirically supportable imputation is possible for them.

**Temporal coherence.** The interpolated variables maintain their within-location autocorrelation structure. The five-day cap, set in response to the temporal structural break analysis, prevents the interpolation from extending across genuine data voids.

**Distributional fidelity.** The Random Forest method within MICE draws imputed values from the observed empirical distribution of each variable, preserving marginal distributions and preventing variance shrinkage.

**Outcome independence.** The weather-conditionality test confirmed that sunshine missingness does not covary with rainfall amounts. Imputed sunshine values therefore do not introduce a directional bias into the training labels.

**Wind direction coherence.** Wind direction variables are imputed as categorical factors using Random Forest, with each direction variable conditioned on its temporally matched speed and pressure readings. This preserves the physical coupling between concurrent wind speed and direction measurements while respecting the non-ordinal structure of compass-point categories.

**Provenance transparency.** Binary imputation flags for the four ghost-prone variables are retained in the final dataset. These flags enable downstream models or diagnostics to condition on or exclude observations where imputed values carry no empirical anchor at the station level.

```{r}
#| label: save-clean-data
#| include: false

if (!dir.exists("data")) {
  dir.create("data")
}
saveRDS(df_clean, "data/df_clean.rds")
```
